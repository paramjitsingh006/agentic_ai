{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d612a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import XMLOutputParser, JsonOutputParser, PydanticOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2588a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26178be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chat = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c75c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.  ðŸ—¼ðŸ‡«ðŸ‡· \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 22, 'total_tokens': 38, 'completion_time': 0.029090909, 'prompt_time': 0.002139225, 'queue_time': 0.015195203999999999, 'total_time': 0.031230134}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b19f77ea-c821-4d36-8f55-5f98242fedcb-0', usage_metadata={'input_tokens': 22, 'output_tokens': 16, 'total_tokens': 38})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_chat | model\n",
    "response = chain.invoke({\"input\": \"What is the capital of France?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dccbce74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Paris'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"What is the capital of {input}? {format_instructions}\",\n",
    "    partial_variables={\n",
    "        \"format_instructions\": json_parser.get_format_instructions(),\n",
    "    },\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "chain = prompt | model | json_parser\n",
    "response = chain.invoke({\"input\": \"What is the capital of France?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66cdd6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyOutputModel(country='France', capital='Paris', latitude=48.8566, longitude=2.3522, timezone='Europe/Paris')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "class MyOutputModel(BaseModel):\n",
    "    country: str\n",
    "    capital: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    timezone: str\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=MyOutputModel)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You are an helpful AI assisntant. Answer the user question: {input}? return {format_instructions}\",\n",
    "    partial_variables={\n",
    "        \"format_instructions\": pydantic_parser.get_format_instructions(),\n",
    "    },\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "chain = prompt | model | pydantic_parser\n",
    "response = chain.invoke({\"input\": \"What is the capital of France?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bfb0f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movies': [{'actor': 'Tom Hanks'},\n",
       "  {'film': [{'name': 'Forrest Gump'}, {'genre': 'Drama, Romance'}]},\n",
       "  {'film': [{'name': 'Saving Private Ryan'}, {'genre': 'War, Drama'}]},\n",
       "  {'film': [{'name': 'Toy Story'}, {'genre': 'Animation, Adventure, Comedy'}]},\n",
       "  {'film': [{'name': 'Cast Away'}, {'genre': 'Adventure, Drama'}]}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_parser = XMLOutputParser(tags=[\"movies\", \"actor\", \"film\", \"name\", \"genre\"])\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You are an helpful AI assisntant. Answer the user question: {input}? return {format_instructions}\",\n",
    "    partial_variables={\n",
    "        \"format_instructions\": xml_parser.get_format_instructions(),\n",
    "    },\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "chain = prompt | model | xml_parser\n",
    "response = chain.invoke({\"input\": \"tell me some movies with Tom Hanks\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "86ee1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(description=\"The name of the product\")\n",
    "    tentative_price: Optional[float] = Field(default=None, description=\"The price of the product in USD\")\n",
    "    description: str = Field(description=\"A brief description of the product\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cf63e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import  ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "product_parser = PydanticOutputParser(pydantic_object=Product)\n",
    "\n",
    "_prompt_template = PromptTemplate(\n",
    "    template=\"You are a helpful eCommerce Product assistant. Answer the user question: {input}. Return the product information in the format: {format_instructions}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": product_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d5cab955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product(name='iPhone 15 Pro Max', tentative_price=1099.0, description='The latest iPhone, featuring an advanced camera system, a stunning display, and powerful performance.')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate(prompt=_prompt_template),\n",
    "        HumanMessage(content=\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model | product_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Tell me about the latest iPhone.\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
